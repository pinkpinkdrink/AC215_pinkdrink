{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_captioning_inception_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkO9kjtxc1-J"
      },
      "source": [
        "# Inception(frozen)-LSTM\n",
        "This model uses seq2seq architecure with teacher forcing to caption images from MS COCO dataset.\n",
        "\n",
        "Example image from model after training:\n",
        "\n",
        "![](https://drive.google.com/uc?id=1xdcSs3naEnZc5gzhwQTGPCRx2W11qli0)\n",
        "\n",
        "Note that attention can be added upon this architecure, but it takes more time to train."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wml3itRKUdPu"
      },
      "source": [
        "###Importing relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9bgv0dqVWwnf"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "keras = tf.keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IcVDPUyU3pz"
      },
      "source": [
        "##Setting config parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ztSDtCwfXLKe"
      },
      "source": [
        "max_cap_len = 15  # Determines max length of captioning sentences\n",
        "img_dimension = 299 # Determines the height and width of images\n",
        "num_words = 10000 # Determines vocab size to tokenize and train on\n",
        "encoding_size = 512 # Determines dimension of the encodings of images\n",
        "LSTM_size = 512 \n",
        "batch_size = 128\n",
        "n_epochs = 15\n",
        "Buffer_size = 1000\n",
        "validation_and_test_split = 0.2\n",
        "test_to_val_split = 0.5\n",
        "num_examples = None # Determines number of overall read samples. If set to none all samples will be read as long as they don't exceed max_cap_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_ulJ_nMUoEB"
      },
      "source": [
        "##Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFyoS-xaUvTo"
      },
      "source": [
        "###Downloading the MS COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UimWmDlIVLuK"
      },
      "source": [
        "Both this cell and the one below it were copied from a google documentation.\n",
        "\n",
        "I have done some editing like stripping out most of 'a', 'an' and 'the' words as they had little value and were too common.\n",
        "\n",
        "Link of the google doucmenatin:\n",
        "\n",
        "https://www.tensorflow.org/tutorials/text/image_captioning#model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZGcnSjLXZPL",
        "outputId": "c5a5afaa-8d3a-483a-cb2d-455defe75aa8"
      },
      "source": [
        "# Download caption annotation files\n",
        "annotation_folder = '/annotations/'\n",
        "\n",
        "annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
        "                                          cache_subdir=os.path.abspath('.'),\n",
        "                                          origin = 'http://images.cocodataset.org/annotations/annotations_trainval2014.zip',\n",
        "                                          extract = True)\n",
        "annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'\n",
        "os.remove(annotation_zip)\n",
        "\n",
        "# Download image files\n",
        "image_folder = '/train2014/'\n",
        "\n",
        "image_zip = tf.keras.utils.get_file('train2014.zip',\n",
        "                                      cache_subdir=os.path.abspath('.'),\n",
        "                                      origin = 'http://images.cocodataset.org/zips/train2014.zip',\n",
        "                                      extract = True)\n",
        "PATH = os.path.dirname(image_zip) + image_folder\n",
        "os.remove(image_zip)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
            "252878848/252872794 [==============================] - 6s 0us/step\n",
            "252887040/252872794 [==============================] - 6s 0us/step\n",
            "Downloading data from http://images.cocodataset.org/zips/train2014.zip\n",
            "13510574080/13510573713 [==============================] - 277s 0us/step\n",
            "13510582272/13510573713 [==============================] - 277s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jU-OI-bx0mjL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oA_YYdmWYey"
      },
      "source": [
        "###Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gqTx7-7unXyd"
      },
      "source": [
        "# Read the json file\n",
        "annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'\n",
        "with open(annotation_file, 'r') as f:\n",
        "    annotations = json.load(f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FCrgJy1jijAB",
        "outputId": "0a6a77e6-bc83-4322-fc1a-991628b8559b"
      },
      "source": [
        "\n",
        "# Store captions and image names in vectors\n",
        "all_captions = []\n",
        "all_img_name_vector = []\n",
        "\n",
        "for annot in annotations['annotations']:\n",
        "    caption = annot['caption']\n",
        "\n",
        "    #Removing the word 'a' from captions\n",
        "    caption = caption.replace(\" a \",\" \")\n",
        "    caption = caption.replace(\"A \",\"\")\n",
        "    #Removing the word 'an' from captions\n",
        "    caption = caption.replace(\"An \",\"\")\n",
        "    caption = caption.replace(\" an \",\" \")\n",
        "    #Removing the word 'the' from captions\n",
        "    caption = caption.replace(\" the \",\" \")\n",
        "    caption = caption.replace(\"The \",\"\")\n",
        "\n",
        "    #Load only captions that don't exceed maximum length\n",
        "    if len(caption.split(\" \")) > max_cap_len:\n",
        "      continue\n",
        "    else:\n",
        "      caption = '<sos> ' + caption + ' <eos>'\n",
        "      image_id = annot['image_id']\n",
        "      full_coco_image_path = PATH + 'COCO_train2014_' + '%012d.jpg' % (image_id)\n",
        "\n",
        "      all_img_name_vector.append(full_coco_image_path)\n",
        "      all_captions.append(caption)\n",
        "# all_img_name_vector = all_img_name_vector[:6000]\n",
        "# all_captions = all_captions[:6000]\n",
        "# Shuffle captions and image_names together\n",
        "# Set a random state\n",
        "train_captions, img_name_vector = shuffle(all_captions,\n",
        "                                          all_img_name_vector,\n",
        "                                          random_state=42)\n",
        "train_captions = train_captions[:num_examples]\n",
        "img_name_vector = img_name_vector[:num_examples]\n",
        "\n",
        "caption_train, captions_test, img_name_vector_train, img_name_vector_test = train_test_split(train_captions,\n",
        "                                                                      img_name_vector,\n",
        "                                                                      test_size= validation_and_test_split)\n",
        "\n",
        "caption_val, caption_test, img_name_vector_val, img_name_vector_test = train_test_split(captions_test,\n",
        "                                                        img_name_vector_test,\n",
        "                                                        test_size= test_to_val_split)\n",
        "num_samples = len(img_name_vector)\n",
        "assert len(train_captions) == len(img_name_vector)\n",
        "print(\"Loaded %d samples\" %(num_samples))\n",
        "print(\"Loaded %d train samples\" %(len(caption_train)))\n",
        "print(\"Loaded %d valid samples\" %(len(caption_val)))\n",
        "print(\"Loaded %d test samples\" %(len(caption_test)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 409297 samples\n",
            "Loaded 327437 train samples\n",
            "Loaded 40930 valid samples\n",
            "Loaded 40930 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy82Cms1Ww4d"
      },
      "source": [
        "###Tokenizing and padding captions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0lBpZWNds-65",
        "outputId": "b1f9964c-0256-4f20-84a7-6410e056a8db"
      },
      "source": [
        "tok = keras.preprocessing.text.Tokenizer(num_words = num_words\n",
        "                                         ,filters =\"!?,'()_-+=&*$#@.\",oov_token=\"<unk>\")\n",
        "tok.fit_on_texts(caption_train)\n",
        "captions_train = tok.texts_to_sequences(caption_train)\n",
        "if num_words == None:\n",
        "  words = len(tok.word_index)\n",
        "else:\n",
        "  words = num_words\n",
        "captions_train = keras.preprocessing.sequence.pad_sequences(captions_train, padding='post',maxlen=max_cap_len + 2)\n",
        "print(\"Examlpe:\", captions_train[np.random.randint(low=0, high= len(captions_train) - 1,size=1)[0]])\n",
        "print(\"Found %d unique words\" %(words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examlpe: [  2  29  17   6 139 166 106  80  29 263   3   0   0   0   0   0   0]\n",
            "Found 10000 unique words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iuRDMTiQaM8O"
      },
      "source": [
        "captions_valid = tok.texts_to_sequences(caption_val)\n",
        "captions_valid = keras.preprocessing.sequence.pad_sequences(captions_valid, padding='post',maxlen=max_cap_len + 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoyzWUyQWfIa"
      },
      "source": [
        "###Defining preprocessing functions of dataset\n",
        "tf.data api is used for making efficient input pipelines as the data is huge for ram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EIq83coJkhUb"
      },
      "source": [
        "def load_img(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize(img, (img_dimension, img_dimension))\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D7IneqDLw73i"
      },
      "source": [
        "def preprocess_func(path_index, caption):\n",
        "  #Reading the image\n",
        "  path_index = tf.reshape(path_index, ())\n",
        "  path = tf.gather(img_name_vector_train,indices=path_index)\n",
        "  img = load_img(path)#/255.0\n",
        "  #Preprocessing text\n",
        "  teacher_caption = caption[:-1]\n",
        "  tar_caption = caption[1:]\n",
        "  \n",
        "  h_and_c_init = tf.zeros((LSTM_size))\n",
        "   \n",
        "  return (img,h_and_c_init,teacher_caption), tar_caption "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f5wkyHP4b7Cx"
      },
      "source": [
        "def preprocess_func_val(path_index, caption):\n",
        "  #Reading the image\n",
        "  path_index = tf.reshape(path_index, ())\n",
        "  path = tf.gather(img_name_vector_val,indices=path_index)\n",
        "  img = load_img(path)#/255.0\n",
        "  #Preprocessing text\n",
        "  teacher_caption = caption[:-1]\n",
        "  tar_caption = caption[1:]\n",
        "\n",
        "  h_and_c_init = tf.zeros((LSTM_size))\n",
        "  \n",
        "  return (img,h_and_c_init,teacher_caption), tar_caption "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OuCNR4BEvuts"
      },
      "source": [
        "#Creating an array to index each img path for reading \n",
        "path_index_vec_train = np.array(list(range(0,len(img_name_vector_train)))).reshape(-1,1)\n",
        "path_index_vec_val = np.array(list(range(0,len(img_name_vector_val)))).reshape(-1,1)\n",
        "\n",
        "dataset1_train = tf.data.Dataset.from_tensor_slices(path_index_vec_train)\n",
        "dataset2_train = tf.data.Dataset.from_tensor_slices(captions_train)\n",
        "dataset = tf.data.Dataset.zip((dataset1_train,dataset2_train))\n",
        "dataset = dataset.map(preprocess_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "dataset1_val = tf.data.Dataset.from_tensor_slices(path_index_vec_val)\n",
        "dataset2_val = tf.data.Dataset.from_tensor_slices(captions_valid)\n",
        "dataset_val = tf.data.Dataset.zip((dataset1_val,dataset2_val))\n",
        "dataset_val = dataset_val.map(preprocess_func_val, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0kgdFtlRUHgn"
      },
      "source": [
        "dataset = dataset.shuffle(Buffer_size).batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "dataset_val = dataset_val.shuffle(Buffer_size).batch(256,drop_remainder=True).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caHmj9HSZDZ3"
      },
      "source": [
        "##Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImEdM_PVZJAf"
      },
      "source": [
        "###Downloading Inception and freezing it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VXWUIwgnm9_F",
        "outputId": "2c715ee6-8a9c-4257-bfb7-e535cb6f50c7"
      },
      "source": [
        "from keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "\n",
        "incep = keras.applications.inception_v3.InceptionV3(input_shape=(img_dimension,img_dimension,3),\n",
        "                                                    include_top=False)\n",
        "incep.trainable=False\n",
        "incep.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n",
            "87924736/87910968 [==============================] - 0s 0us/step\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oS4vdj0e_V4N",
        "outputId": "bf716a7a-69f3-45ff-e84a-1197825e4d7f"
      },
      "source": [
        "encoder = keras.models.Sequential([\n",
        "                                   keras.layers.Lambda(preprocess_input,input_shape=(img_dimension,img_dimension,3),name=\"preprocessing_layer\"),\n",
        "                                   incep,\n",
        "                                   keras.layers.Dense(encoding_size,activation='relu',name=\"encoding_layer\"),\n",
        "                                   keras.layers.Reshape((8*8,encoding_size),name=\"reshape_layer\")\n",
        "],name=\"Encoder\")\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"Encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " preprocessing_layer (Lambda  (None, 299, 299, 3)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n",
            "                                                                 \n",
            " encoding_layer (Dense)      (None, 8, 8, 512)         1049088   \n",
            "                                                                 \n",
            " reshape_layer (Reshape)     (None, 64, 512)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,851,872\n",
            "Trainable params: 1,049,088\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUjt2xflbWyS"
      },
      "source": [
        "###Completing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olcS9GvPKUOW"
      },
      "source": [
        "####Building attention mechanism\n",
        "This is Bahdanau attention, A soft attention mechanism that works through linear combination of previous state and the whole image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ntAUw73ONfBJ"
      },
      "source": [
        "W1 = keras.layers.Dense(512,name=\"W1\")\n",
        "W2 = keras.layers.Dense(512,name=\"W2\")\n",
        "V = keras.layers.Dense(1,name=\"V\")\n",
        "repeater = keras.layers.RepeatVector(8*8)\n",
        "doter = keras.layers.Dot(axes=1)\n",
        "concatenator = keras.layers.Concatenate()\n",
        "\n",
        "def attention_step(enc,h_prev):\n",
        "  h = repeater(h_prev)\n",
        "  score = tf.nn.tanh(W1(enc)+ W2(h))\n",
        "\n",
        "  alphas =tf.nn.softmax(V(score),axis=1)\n",
        "\n",
        "  context = doter([alphas,enc])\n",
        "  return context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3r5kLZRLBRA"
      },
      "source": [
        "####Building the deoder\n",
        "\n",
        "This decoder goes one time-step at a time.\n",
        "\n",
        "So, a custom training function is required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g9cRgkpzjZuc",
        "outputId": "8265b62e-0bd3-4498-dbbb-4c5ea2f6527f"
      },
      "source": [
        "encodings = keras.layers.Input(shape=(8*8,encoding_size))\n",
        "\n",
        "init_h = keras.layers.Input(shape=(LSTM_size))\n",
        "init_c = keras.layers.Input(shape=(LSTM_size))\n",
        "\n",
        "teacher_forcing = keras.layers.Input(shape=(1))\n",
        "\n",
        "embedding_layer = keras.layers.Embedding(words+1,256,)\n",
        "\n",
        "\n",
        "context_prev_tar_concat_layer = keras.layers.Concatenate()\n",
        "decoder_lstm_layer = keras.layers.LSTM(LSTM_size,return_state=True,dropout=0.2)\n",
        "decoder_dense_layer = keras.layers.Dense(words+1,activation='softmax')\n",
        "\n",
        "h = init_h\n",
        "\n",
        "c = init_c\n",
        "\n",
        "context = attention_step(encodings,h)\n",
        "\n",
        "embedds = embedding_layer(teacher_forcing)\n",
        "\n",
        "decoder_lstm_input = context_prev_tar_concat_layer([context,embedds])\n",
        "  \n",
        "h , _ , c = decoder_lstm_layer(decoder_lstm_input,initial_state=[h,c])\n",
        "  \n",
        "out = decoder_dense_layer(h)\n",
        "\n",
        "decoder = keras.models.Model([encodings,init_h,init_c,teacher_forcing],[out,h,c])\n",
        "decoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 64, 512)]    0           []                               \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVector)   (None, 64, 512)      0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " W1 (Dense)                     (None, 64, 512)      262656      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " W2 (Dense)                     (None, 64, 512)      262656      ['repeat_vector[0][0]']          \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 64, 512)     0           ['W1[0][0]',                     \n",
            " da)                                                              'W2[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.math.tanh (TFOpLambda)      (None, 64, 512)      0           ['tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " V (Dense)                      (None, 64, 1)        513         ['tf.math.tanh[0][0]']           \n",
            "                                                                                                  \n",
            " tf.nn.softmax (TFOpLambda)     (None, 64, 1)        0           ['V[0][0]']                      \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 1, 512)       0           ['tf.nn.softmax[0][0]',          \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1, 256)       2560256     ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 1, 768)       0           ['dot[0][0]',                    \n",
            "                                                                  'embedding[0][0]']              \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 512),        2623488     ['concatenate_3[0][0]',          \n",
            "                                 (None, 512),                     'input_3[0][0]',                \n",
            "                                 (None, 512)]                     'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10001)        5130513     ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,840,082\n",
            "Trainable params: 10,840,082\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxUZBJuHbcmU"
      },
      "source": [
        "##Defining custom loss function\n",
        "This loss function masks the padded steps and also one-hot enodes the targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QA2cPznzEFF7"
      },
      "source": [
        "def sparse_it_up(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "\n",
        "  real = tf.cast(real,tf.int64)\n",
        "  real = tf.one_hot(real,words+1,axis=-1)\n",
        "\n",
        "  loss_ = tf.losses.categorical_crossentropy(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rucb1OR-b8vh"
      },
      "source": [
        "##Defining the custom train loop\n",
        "\n",
        "This custorm training loop was inspired from the google documentation linked above aswell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VTYPdmHjrD4g"
      },
      "source": [
        "optimizer = keras.optimizers.Adam()\n",
        "\n",
        "@tf.function\n",
        "def train_step(img,init_state,teacher,target):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    encodings = encoder(img)\n",
        "    h = init_state\n",
        "    c = init_state\n",
        "    loss = 0\n",
        "    for i in range(max_cap_len+1):\n",
        "      dec_inp = teacher[:,i:i+1]\n",
        "      o, h , c = decoder([encodings,h,c,dec_inp])\n",
        "\n",
        "      loss += sparse_it_up(target[:,i],o) \n",
        "\n",
        "  total_loss = (loss / int(target.shape[1]))\n",
        "\n",
        "  trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, trainable_variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "  return loss, total_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EiS97RLM9Mxo"
      },
      "source": [
        "'''This function is for forward passing features for calculating losses with no backprop'''\n",
        "@tf.function\n",
        "def valid_step(img,init_state,teacher,target):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    encodings = encoder(img)\n",
        "    h = init_state\n",
        "    c = init_state\n",
        "    loss = 0\n",
        "    for i in range(max_cap_len+1):\n",
        "      dec_inp = teacher[:,i:i+1]\n",
        "      o, h , c = decoder([encodings,h,c,dec_inp])\n",
        "\n",
        "      loss += sparse_it_up(target[:,i],o) \n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O6FDyjucCdi"
      },
      "source": [
        "##Training the model\n",
        "One training epoch takes about 35 minutes on google colab with gpu.\n",
        "\n",
        "So, get busy doing something else for a while! or just go for a smaller num_examples set from the configuration cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LxqeXgqKiCTL"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI9tncQhsSRr"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "prev_loss = np.inf\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, ((img, s, teacher) ,target)) in enumerate(dataset):\n",
        "        batch_loss, t_loss = train_step(img, s, teacher ,target)\n",
        "        total_loss += t_loss\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
        "              epoch + 1, batch, batch_loss.numpy() / int(target.shape[1])))\n",
        "    \n",
        "    val_loss=0\n",
        "\n",
        "    for (i, ((img, s, teacher) ,target)) in enumerate(dataset_val):\n",
        "      val_loss += valid_step(img, s, teacher ,target)\n",
        "    \n",
        "    val_loss = val_loss.numpy()/((i+1)*(max_cap_len+1))\n",
        "    print(\"val_loss=\",val_loss)\n",
        "    \n",
        "    #This code makes sure we only save the best val_loss score weights\n",
        "    if val_loss < prev_loss:\n",
        "      print(\"Model_imporved. Saving..\")\n",
        "\n",
        "      encoder.save(\"encoder.hdf5\")\n",
        "      decoder.save(\"decoder.hdf5\")\n",
        "    \n",
        "    else:\n",
        "      print(\"Model didn't imporve.\")\n",
        "\n",
        "    prev_loss = val_loss\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd_H6wTFsoL_"
      },
      "source": [
        "os.mkdir('./tokenizer/')\n",
        "import pickle\n",
        "# saving\n",
        "with open('./tokenizer/tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tok, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crRIZHTSIXtA"
      },
      "source": [
        "# Loading the best validation accuracy score weights\n",
        "encoder.load_weights(\"encoder.hdf5\")\n",
        "decoder.load_weights(\"decoder.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSMHIZ_Ws6KD"
      },
      "source": [
        "with open('./tokenizer/tokenizer.pickle', 'rb') as handle:\n",
        "    tok = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjRaNQuuV9jJ"
      },
      "source": [
        "##Prediction function\n",
        "This function takes its input as path of an image and captions it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAgqyXYFxPXm"
      },
      "source": [
        "max_cap_len = 15  # Determines max length of captioning sentences\n",
        "img_dimension = 299 # Determines the height and width of images\n",
        "num_words = 10000 # Determines vocab size to tokenize and train on\n",
        "LSTM_size = 512 \n",
        "# Loading the best validation accuracy score weights\n",
        "encoder.load_weights(\"encoder.hdf5\")\n",
        "decoder.load_weights(\"decoder.hdf5\")\n",
        "\n",
        "with open('./tokenizer/tokenizer.pickle', 'rb') as handle:\n",
        "    tok = pickle.load(handle)\n",
        "\n",
        "def caption_image(encoder, decoder, path):\n",
        "  image = load_img(path)#/255.0\n",
        "  encodings = encoder.predict(tf.reshape(image,(1,img_dimension,img_dimension,3)))\n",
        "  texts = [\"<sos>\"]\n",
        "  h = np.zeros((1,LSTM_size))\n",
        "  c = np.zeros((1,LSTM_size))\n",
        "  for _ in range(max_cap_len + 1):\n",
        "    dec_inp = np.array(tok.word_index.get(texts[-1])).reshape(1,-1)\n",
        "    #print(dec_inp)\n",
        "    props,h,c = decoder.predict([encodings,h,c ,dec_inp])\n",
        "    props= props[0]\n",
        "    idx = np.argmax(props)\n",
        "    texts.append(tok.index_word.get(idx))\n",
        "    if idx == tok.word_index['<eos>']:\n",
        "      break\n",
        "  if tok.word_index.get(texts[-1]) != tok.word_index['<eos>']:\n",
        "    texts.append('<eos>')\n",
        "\n",
        "  print(texts)\n",
        "  print(' '.join(texts))\n",
        "  plt.imshow(image/255.0)\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOFUIurqsXxi"
      },
      "source": [
        "def calculate_bleu(path, caption):\n",
        "  image = load_img(path)#/255.0\n",
        "  encodings = encoder.predict(tf.reshape(image,(1,img_dimension,img_dimension,3)))\n",
        "  texts = [\"<sos>\"]\n",
        "  h = np.zeros((1,LSTM_size))\n",
        "  c = np.zeros((1,LSTM_size))\n",
        "  for _ in range(max_cap_len + 1):\n",
        "    dec_inp = np.array(tok.word_index.get(texts[-1])).reshape(1,-1)\n",
        "    #print(dec_inp)\n",
        "    props,h,c = decoder.predict([encodings,h,c ,dec_inp])\n",
        "    props= props[0]\n",
        "    idx = np.argmax(props)\n",
        "    texts.append(tok.index_word.get(idx))\n",
        "    if idx == tok.word_index['<eos>']:\n",
        "      break\n",
        "  if tok.word_index.get(texts[-1]) != tok.word_index['<eos>']:\n",
        "    texts.append('<eos>')\n",
        "  bleu_score = sentence_bleu(caption.split(' '), texts, smoothing_function=smoothing.method1)\n",
        "  return bleu_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKEelp1pt_S8"
      },
      "source": [
        "bleu_score = 0\n",
        "smoothing = SmoothingFunction()\n",
        "for i in range(len(img_name_vector_test)):\n",
        "  bleu_score += calculate_bleu(img_name_vector_test[i], caption_test[i])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrePvtkWzuUT"
      },
      "source": [
        "print('bleu score on test images:', bleu_score/len(img_name_vector_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK--sOb_WQYE"
      },
      "source": [
        "###Some random predictions for fun.\n",
        "Apparently the model performs well, but it sometimes deviates from its desired destination when it starts describing some details.\n",
        "\n",
        "I have split some of the predections into the good, the meh and the ugly.\n",
        "\n",
        "Keep in mind that most of the predections i tried on my own fell into 'the good' region."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emVUi-ikqADS"
      },
      "source": [
        "\n",
        "#caption_val, caption_test, img_name_vector_val, img_name_vector_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6273Omjth6c"
      },
      "source": [
        "caption_test[100].split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttw7WUT0c7NE"
      },
      "source": [
        "\n",
        "caption_image(img_name_vector_test[100])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R4wGr0xfULW"
      },
      "source": [
        "print(caption_test[1])\n",
        "caption_image(img_name_vector_test[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB2iH0fjf_B1"
      },
      "source": [
        "print(caption_test[23])\n",
        "caption_image(img_name_vector_test[23])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1OQKhB0pD-i"
      },
      "source": [
        "print(caption_test[50])\n",
        "caption_image(img_name_vector_test[50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNO6tGVT9-Vn"
      },
      "source": [
        "print(caption_test[48])\n",
        "caption_image(img_name_vector_test[48])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir7BB0Fo-g9R"
      },
      "source": [
        "print(caption_test[22])\n",
        "caption_image(img_name_vector_test[22])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLAjyT1CPRum"
      },
      "source": [
        "##Saving the dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6DblLu8q_sN"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tok, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}