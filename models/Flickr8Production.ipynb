{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Flickr8Production.ipynb","provenance":[],"authorship_tag":"ABX9TyNocNfW/+v2P1lmJ2xpKLU0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-expPlJ2WxCq","executionInfo":{"status":"ok","timestamp":1638083085726,"user_tz":360,"elapsed":20830,"user":{"displayName":"anita mahinpei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10893440274338475761"}},"outputId":"2f99c636-826f-4ab5-c3c6-cdf4d3dc359a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"SXf8nJisXEup","executionInfo":{"status":"ok","timestamp":1638083093275,"user_tz":360,"elapsed":342,"user":{"displayName":"anita mahinpei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10893440274338475761"}}},"source":["import os\n","os.chdir('/content/drive/MyDrive/AC215 Project/dataset')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zo2l2zbVWdXd","executionInfo":{"status":"ok","timestamp":1638083409860,"user_tz":360,"elapsed":6858,"user":{"displayName":"anita mahinpei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10893440274338475761"}},"outputId":"da34bb1e-358d-4bd1-de78-d85743c16d86"},"source":["from pickle import load\n","from numpy import argmax\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.applications.vgg16 import VGG16\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.vgg16 import preprocess_input\n","from keras.models import Model\n","from keras.models import load_model\n"," \n","# extract features from each photo in the directory\n","def extract_features(filename):\n","\t# load the model\n","\tmodel = VGG16()\n","\t# re-structure the model\n","\tmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n","\t# load the photo\n","\timage = load_img(filename, target_size=(224, 224))\n","\t# convert the image pixels to a numpy array\n","\timage = img_to_array(image)\n","\t# reshape data for the model\n","\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\t# prepare the image for the VGG model\n","\timage = preprocess_input(image)\n","\t# get features\n","\tfeature = model.predict(image, verbose=0)\n","\treturn feature\n"," \n","# map an integer to a word\n","def word_for_id(integer, tokenizer):\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == integer:\n","\t\t\treturn word\n","\treturn None\n"," \n","# generate a description for an image\n","def generate_desc(model, tokenizer, photo, max_length):\n","\t# seed the generation process\n","\tin_text = 'startseq'\n","\t# iterate over the whole length of the sequence\n","\tfor i in range(max_length):\n","\t\t# integer encode input sequence\n","\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n","\t\t# pad input\n","\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n","\t\t# predict next word\n","\t\tyhat = model.predict([photo,sequence], verbose=0)\n","\t\t# convert probability to integer\n","\t\tyhat = argmax(yhat)\n","\t\t# map integer to word\n","\t\tword = word_for_id(yhat, tokenizer)\n","\t\t# stop if we cannot map the word\n","\t\tif word is None:\n","\t\t\tbreak\n","\t\t# stop if we predict the end of the sequence\n","\t\tif word == 'endseq':\n","\t\t\tbreak\n","    # append as input for generating the next word\n","\t\tin_text += ' ' + word\n","\treturn in_text\n"," \n","# load the tokenizer\n","tokenizer = load(open('tokenizer.pkl', 'rb'))\n","# pre-define the max sequence length (from training)\n","max_length = 34\n","# load the model\n","model = load_model('model_3.h5')\n","# load and prepare the photograph\n","photo = extract_features('/content/surfer.png')\n","# generate description\n","description = generate_desc(model, tokenizer, photo, max_length)\n","print(description[9:])"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["the man is riding the water\n"]}]}]}